{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import moviepy.editor as mp\n",
    "import librosa\n",
    "import os\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, Reshape, Dropout, LeakyReLU, Flatten, Input, \n",
    "                                     BatchNormalization, Conv2D, Conv2DTranspose)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from IPython.display import Audio, display, HTML, IFrame\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "class FileFormatError(IOError): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(file_name:str):\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(), 'tmp')):\n",
    "        os.mkdir(os.path.join(os.getcwd(), 'tmp'))\n",
    "    tmp_dir = os.path.join(os.getcwd(), 'tmp')\n",
    "    f = file_name.replace('.mp3', '').replace('.mp4','').replace('.wmv', '') + '.wav'\n",
    "    f = os.path.join(tmp_dir, f)\n",
    "    if file_name.endswith('.wav'):\n",
    "        return file_name\n",
    "    elif file_name.endswith('.mp3'):\n",
    "        audio = mp.AudioFileClip(file_name); audio.write_audiofile(f, codec='pcm_s32le')\n",
    "        return f\n",
    "    elif file_name.endswith('.mp4') or file_name.endswith('.wmv'):\n",
    "        video = mp.VideoFileClip(file_name); video.audio.write_audiofile(f, codec='pcm_s32le')\n",
    "        return f\n",
    "    else:\n",
    "        raise FileFormatError(\"Supported Formats are 'wav', 'mp3', 'mp4', 'wmv'.\")\n",
    "\n",
    "def prepare_dataset(dataset_path, json_path, sample_rate=22050, n_mfcc=13, hop_length=512, n_fft=2048, samples_to_consider=60):\n",
    "    '''\n",
    "        dataset_path: \n",
    "        json_path: \n",
    "        n_mfcc: \n",
    "        hop_length: \n",
    "        n_fft: \n",
    "    '''\n",
    "    samples_to_consider *= sample_rate\n",
    "    data = dict(mappings=[], labels=[], MFCCs=[], files=[])\n",
    "    prev_i = 0\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        for f in filenames:\n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            file_path = convert_to_wav(file_path)\n",
    "            signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "            if len(signal) >= samples_to_consider:\n",
    "                signal = signal[:samples_to_consider]\n",
    "\n",
    "                MFCCs = librosa.feature.mfcc(signal, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "                data['labels'].append(i-1)\n",
    "                data['MFCCs'].append(MFCCs.T.tolist())\n",
    "                data['files'].append(file_path)\n",
    "                if abs(prev_i - i) == 1:\n",
    "                    print(f'{file_path}: {i-1}')\n",
    "                    prev_i += 1\n",
    "    with open(json_path, 'w') as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "        fp.close()\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    '''\n",
    "        data_path: Takes in the json file path\n",
    "    '''\n",
    "    with open(data_path, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "        X = np.array(data['MFCCs'])\n",
    "        y = np.array(data['labels'])\n",
    "        return X, y\n",
    "    \n",
    "def convert_to_batches(data, batch_size=10):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(buffer_size=100)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# D:\\A\\audio_processing\\data\\bed\n",
    "prepare_dataset(r'D:\\A\\Trimester_4_Mini_Project\\data\\audio_dataset\\karoke\\english', 'music_data.json', 44100, 20, samples_to_consider=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X, y = load_dataset('music_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.min(), X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((-1, 1))\n",
    "scaler.fit([[-650], [300]])\n",
    "scaled_X = []\n",
    "for i in range(X.shape[0]):\n",
    "    scaled_X.append(scaler.transform(X[i]).tolist())\n",
    "# scaled_X = scaler.transform(X.reshape(-1, 20))\n",
    "# scaled_X = scaled_X.reshape(40, -1, 20)\n",
    "scaled_X = np.array(scaled_X)\n",
    "scaled_X.shape\n",
    "X = X[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X.min(), scaled_X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.min(), X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_model(input_shape:tuple=(10336, 13, 1)):\n",
    "    generator = Sequential(name='generator')\n",
    "    generator.add(Input(shape=input_shape))\n",
    "#     generator.add(Flatten())\n",
    "#     generator.add(Dense(10336*13))\n",
    "#     generator.add(Reshape([25840, 20, 1]))\n",
    "    generator.add(Conv2DTranspose(64, (3,3), padding='same'))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(Conv2DTranspose(32, (3,3), padding='same'))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(Conv2DTranspose(16, (3,3), padding='same'))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(Conv2DTranspose(8, (3,3), padding='same'))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(Conv2DTranspose(4, (3,3), padding='same'))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(Conv2DTranspose(2, (3,3), padding='same'))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(Conv2DTranspose(1, (3,3), padding='same'))\n",
    "    \n",
    "    discriminator = Sequential(name='discriminator')\n",
    "    discriminator.add(Input(shape=input_shape))\n",
    "    discriminator.add(Conv2D(64, (3,3), padding='same'))\n",
    "    discriminator.add(Dropout(0.5))\n",
    "    discriminator.add(Conv2D(32, (3,3), padding='same'))\n",
    "    discriminator.add(Dropout(0.5))\n",
    "    discriminator.add(Conv2D(16, (3,3), padding='same'))\n",
    "    discriminator.add(Dropout(0.5))\n",
    "    discriminator.add(Conv2D(8, (3,3), padding='same'))\n",
    "    discriminator.add(Dropout(0.5))\n",
    "    discriminator.add(Conv2D(4, (3,3), padding='same'))\n",
    "    discriminator.add(Dropout(0.5))\n",
    "    discriminator.add(Conv2D(2, (3,3), padding='same'))\n",
    "    discriminator.add(Dropout(0.5))\n",
    "    discriminator.add(Conv2D(1, (3,3), padding='same'))\n",
    "    discriminator.add(Dropout(0.5))\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    GAN = Sequential([generator, discriminator], name='GAN')\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    GAN.layers[0].summary()\n",
    "    GAN.layers[1].summary()\n",
    "    return GAN\n",
    "\n",
    "def train_gan(model, epochs, dataset, batch_size=10, input_shape=[10336, 20, 1]):\n",
    "    generator, discriminator = model.layers\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Currently on Epoch {epoch+1}')\n",
    "\n",
    "        for i, X_batch in enumerate(dataset):\n",
    "            i += 1\n",
    "            if i % 100 == 0:\n",
    "                print(f'\\t Currently on batch number {i} of {len(data) // batch_size}')\n",
    "\n",
    "            # DISCRIMINATOR Training Phase\n",
    "            noise = tf.random.normal(shape=[batch_size] + input_shape)\n",
    "            gen_audio = generator(noise)\n",
    "            X_fake_vs_real = tf.concat([gen_audio, tf.dtypes.cast(X_batch, tf.float32)], axis=0)\n",
    "            y1 = tf.constant([[0.0]]*batch_size + [[1.0]]*batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_vs_real, y1)\n",
    "\n",
    "            # GENERATOR Training Phase\n",
    "            noise = tf.random.normal(shape=[batch_size] + input_shape)\n",
    "            y2 = tf.constant([[1.0]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            GAN.train_on_batch(noise, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GAN = gan_model(input_shape=(10336, 20, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = convert_to_batches(X)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    print(d.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_gan(model=GAN, epochs=5, dataset=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audios in data:\n",
    "    print(audios.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.layers[0](audios)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_data = scaler.inverse_transform(np.array(GAN.layers[0](audios)[0]).reshape(10336, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_data[inv_data == np.inf].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_data.min(), inv_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(inv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.feature.inverse.mfcc_to_audio(np.array(GAN.layers[0](audios)[0]).reshape(10336, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(librosa.feature.inverse.mfcc_to_audio(np.array(GAN.layers[0](audios)[0]).reshape(10336, 20)), rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
